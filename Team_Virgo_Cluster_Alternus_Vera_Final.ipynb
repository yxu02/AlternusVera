{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team Virgo Cluster - Alternus Vera Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "m_x2mbHBQpRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Alternus Vera Project (Team Virgo Cluster) - Final"
      ]
    },
    {
      "metadata": {
        "id": "gjy0OwF6r8ib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Due December 11, 2018\n",
        "By Team Virgo Cluster\n",
        "\n",
        "### About this Notebook\n",
        "\n",
        "This python notebook downloads csv files from different sources uploaded by\n",
        "the individual members of the team working on each factor(s).\n",
        "\n",
        "After downloading the csv files, the factor columns are extracted. Using\n",
        "weighted values and factor score/ranks, we generate a score to determine \"fake\"-ness of\n",
        "each news article. Polynomial equation is provided in this notebook.\n",
        "\n",
        "Since this notebook is the last stage of the pipeline, and generates the final\n",
        "aggregated score for fake news classification, **this notebook can be\n",
        "considered the official notebook of our Alternus Vera project**.\n",
        "\n",
        "However, please refer to the **individual notebooks** and **combined (team) notebook**\n",
        "to see how the individual csv files are generated one per factor. The derivations are done\n",
        "in smaller notebooks, and only aggregations and generating polynomial\n",
        "are done here. All relevant references are made in individual notebooks."
      ]
    },
    {
      "metadata": {
        "id": "8Le_zBnvO9Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### About Team Virgo Cluster\n",
        "\n",
        "###  Contributions\n",
        "\n",
        "Sy Le (006088940) : data import and wrangling, tokenization, remove stopwords, remove stemmings, feature selection using Context of the statement and Social reliability\n",
        "\n",
        "Mojdeh Keykhanzadeh(008129589) : remove punctuation , apply ngrams,researched about IBM Faireness , Sentiment Analysis of text , Frequency of word visualization ,Topic modeling using Gensim , finding cosine similarity score of title and text\n",
        "\n",
        "Hyunwook Shin (012507417) : Coverage Score and Political Bias/Spectrum Analysis, Data enrichment: all news dataset (50K+ articles), political messages dataset (LDA, TF-IDF, MultinomialNB, random forrest, word2vec, doc2vec), identifying factors, and assigning weightage to individual factors.\n",
        "\n",
        "Lin Cheng (012484459) : Interpret and transform data, use TF-IDF Vectorizer with customized tokenizer + SVD to produce a matrix, apply different classifiers and hyperparameter tuning and build a model with 95.6% accuracy\n",
        "\n",
        "Yu Xu (012502048): Explored ways to gather topics from the dataset. Explored tf-idf ranking. Explored pipeline + GridSearch for the best n_component of LDA for logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "vH8lGutKNBYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Notebooks\n",
        "\n",
        "### Team Notebook\n",
        "\n",
        "**Combined notebook** can be found here, but to cut down run time and save resources, we used individual notebooks to run distillation and scoring for each factor. So please do not run the combined notebook, but simply refer to it as the code source.\n",
        "\n",
        "https://colab.research.google.com/drive/1bOoY6V0ytxSigKuZ6lJntNWJJcTM_6wU#scrollTo=myrJOvEVIhue\n",
        "\n",
        "### Individual Notebooks\n",
        "\n",
        "**Hyunwook Notebook**\n",
        "https://colab.research.google.com/drive/1gOvKRrE7g7ldiNIpoYbkx3hnOW9LT66T#scrollTo=BXdP1JmmfaSp\n",
        "\n",
        "**Mojdeh Notebook**\n",
        "https://colab.research.google.com/drive/1Xz_-XGbzTdK53INTXI-WqOcDW5gWbl3o#scrollTo=XUZqgzzOIQ_M&uniqifier=2\n",
        "\n",
        "**Sy Notebook**\n",
        "https://colab.research.google.com/drive/1QfCxEI_agvoMclqVujmJskXTspUSeDAH\n",
        "\n",
        "**Lin Notebook**\n",
        "https://colab.research.google.com/drive/1dVuCq4kcgIhl9vK1CzR8EFoWqi0VzHT9\n",
        "\n",
        "**Gene Notebook**\n",
        "https://colab.research.google.com/drive/17Veeq4ovc7ToWbhTMGEcfPJ6TmOzoEHJ\n",
        "\n",
        "(Data processing template by Gene for Aggregation)\n",
        "https://colab.research.google.com/drive/1rLCLUZlNylQ0t7d_-lYaAi5GKisHn290#scrollTo=Ep7WNDIqg4pk"
      ]
    },
    {
      "metadata": {
        "id": "oHk0PCfrrRRc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ]
    },
    {
      "metadata": {
        "id": "cXXQkvXzrF5m",
        "colab_type": "code",
        "outputId": "4831e81a-414e-4fdd-f329-bf32b553272d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# dependencies\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "# from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_selection import chi2\n",
        "from string import punctuation\n",
        "from nltk import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "iErqgBa7rjv3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Individual CSV Files (Factors)\n",
        "\n",
        "The individual CSV files should have the same rows (fake news and all news dataset concatenated together), with articles in the same order as\n",
        "prepared originally by Gene.\n",
        "\n",
        "1. Fake news comes first before Non-fake (all) news\n",
        "2. Ensuring that the counts are as follows:\n",
        "\n",
        "```\n",
        "<your_labeled_csv_data>.type.value_counts()\n",
        "0    51507\n",
        "1    11492\n",
        "Name: type, dtype: int64\n",
        " ```\n",
        " \n",
        " 3. Ensuring that the labels are complete with no \"holes\""
      ]
    },
    {
      "metadata": {
        "id": "P0sNcQflttmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_parsed_data(url):\n",
        "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFmt5gTP98Uu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Master Dataset"
      ]
    },
    {
      "metadata": {
        "id": "a_TzjkGz99o3",
        "colab_type": "code",
        "outputId": "eb897b92-9ab3-4dd8-bc87-e420984cba1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "data_kg_fake_news = get_parsed_data('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv')\n",
        "data_kg_fake_news.loc[data_kg_fake_news['type']!='bs', 'type'] = 0\n",
        "data_kg_fake_news.loc[data_kg_fake_news['type']=='bs', 'type'] = 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ezQiM5MNkAZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "de514dc2-b6ed-4690-c45b-bbc668470e17"
      },
      "cell_type": "code",
      "source": [
        "data_kg_nonfake_news = get_parsed_data('https://github.com/synle/AlternusVera/releases/download/v0/articles1.csv')\n",
        "data_kg_nonfake_news.rename(columns={\"content\": \"text\"}, inplace=True)\n",
        "data_kg_nonfake_news['type'] = 0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4_s4h6XDkA06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([data_kg_fake_news[['title','text','type']], data_kg_nonfake_news[['title','text','type']]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNvvJJVV-SH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verify dimensions"
      ]
    },
    {
      "metadata": {
        "id": "SLhLZ9Re-Tyn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert all_data.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pkg1BJ0vrmr6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gene "
      ]
    },
    {
      "metadata": {
        "id": "BoKMVKc1rQSe",
        "colab_type": "code",
        "outputId": "b93e5f1e-3dda-446c-bfaa-811136405c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "w2v_d2v_factors = pd.read_csv(io.StringIO(requests.get('https://github.com/synle/AlternusVera/releases/download/v0/fake_news_w2v_d2v_only.csv', \\\n",
        "                                                       verify=False).content.decode('utf-8')), sep=',', header=None, names=['text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qr9Vnu4ACvvJ",
        "colab_type": "code",
        "outputId": "7d61b02e-751f-4936-ac9a-bfefe302a484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "w2v_d2v_factors.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_w2v_mean</th>\n",
              "      <th>title_w2v_mean</th>\n",
              "      <th>text_d2v_mean</th>\n",
              "      <th>title_d2v_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.052476</td>\n",
              "      <td>0.066654</td>\n",
              "      <td>-0.220385</td>\n",
              "      <td>-0.114133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.126095</td>\n",
              "      <td>-0.309628</td>\n",
              "      <td>-0.048451</td>\n",
              "      <td>0.017952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.095904</td>\n",
              "      <td>-0.209579</td>\n",
              "      <td>-0.118836</td>\n",
              "      <td>-0.079925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.027249</td>\n",
              "      <td>-0.071950</td>\n",
              "      <td>-0.038647</td>\n",
              "      <td>-0.168344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.075030</td>\n",
              "      <td>-0.066515</td>\n",
              "      <td>-0.155317</td>\n",
              "      <td>-0.074950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   text_w2v_mean  title_w2v_mean  text_d2v_mean  title_d2v_mean\n",
              "0      -0.052476        0.066654      -0.220385       -0.114133\n",
              "1      -0.126095       -0.309628      -0.048451        0.017952\n",
              "2      -0.095904       -0.209579      -0.118836       -0.079925\n",
              "3      -0.027249       -0.071950      -0.038647       -0.168344\n",
              "4      -0.075030       -0.066515      -0.155317       -0.074950"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "Elo9-tKuCd7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert w2v_d2v_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmJ7uhRArn31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mojdeh"
      ]
    },
    {
      "metadata": {
        "id": "Tiji-Uq_rrvE",
        "colab_type": "code",
        "outputId": "fd9cbe63-bd47-457b-afeb-da3755664df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "sentiment_factors = get_parsed_data('https://raw.githubusercontent.com/mojdehkeykhanzadeh/NLP_Proj/master/all_news_sentiment.csv')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8sM7Ik6tJq0y",
        "colab_type": "code",
        "outputId": "b0de23a1-973a-436a-c7cc-a066a2cacdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2006
        }
      },
      "cell_type": "code",
      "source": [
        "sentiment_factors"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title_senti_neg</th>\n",
              "      <th>title_senti_neu</th>\n",
              "      <th>title_senti_pos</th>\n",
              "      <th>title_senti_cmpd</th>\n",
              "      <th>text_senti_neg</th>\n",
              "      <th>text_senti_neu</th>\n",
              "      <th>text_senti_pos</th>\n",
              "      <th>text_senti_cmp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.4588</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.375</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>0.209</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.887</td>\n",
              "      <td>0.050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8957</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.7783</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.517</td>\n",
              "      <td>0.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9517</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9936</td>\n",
              "      <td>0.352</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.893</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9559</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.813</td>\n",
              "      <td>0.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.4588</td>\n",
              "      <td>0.317</td>\n",
              "      <td>0.528</td>\n",
              "      <td>0.154</td>\n",
              "      <td>-0.9836</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.3400</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.678</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.1027</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.902</td>\n",
              "      <td>0.054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>-0.4019</td>\n",
              "      <td>0.243</td>\n",
              "      <td>0.608</td>\n",
              "      <td>0.149</td>\n",
              "      <td>-0.8402</td>\n",
              "      <td>0.151</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>-0.3818</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.698</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9933</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.791</td>\n",
              "      <td>0.209</td>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>-0.4215</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9607</td>\n",
              "      <td>0.148</td>\n",
              "      <td>0.775</td>\n",
              "      <td>0.077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.769</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.7964</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.674</td>\n",
              "      <td>0.267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.769</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.5106</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.325</td>\n",
              "      <td>-0.9783</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8481</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.782</td>\n",
              "      <td>0.136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>0.6597</td>\n",
              "      <td>0.172</td>\n",
              "      <td>0.312</td>\n",
              "      <td>0.516</td>\n",
              "      <td>0.9899</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.706</td>\n",
              "      <td>0.214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>0.163</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.248</td>\n",
              "      <td>0.9531</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.152</td>\n",
              "      <td>-0.8750</td>\n",
              "      <td>0.435</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.1027</td>\n",
              "      <td>0.198</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.221</td>\n",
              "      <td>-0.8481</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.722</td>\n",
              "      <td>0.067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.823</td>\n",
              "      <td>0.177</td>\n",
              "      <td>-0.6124</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.7184</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.756</td>\n",
              "      <td>0.244</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>-0.7506</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.632</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9924</td>\n",
              "      <td>0.173</td>\n",
              "      <td>0.785</td>\n",
              "      <td>0.042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8402</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.838</td>\n",
              "      <td>0.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.7269</td>\n",
              "      <td>0.251</td>\n",
              "      <td>0.539</td>\n",
              "      <td>0.210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62969</th>\n",
              "      <td>49970</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.727</td>\n",
              "      <td>0.178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62970</th>\n",
              "      <td>49971</td>\n",
              "      <td>-0.4767</td>\n",
              "      <td>0.307</td>\n",
              "      <td>0.693</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.8625</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62971</th>\n",
              "      <td>49972</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.2434</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.805</td>\n",
              "      <td>0.099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62972</th>\n",
              "      <td>49973</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9643</td>\n",
              "      <td>0.035</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62973</th>\n",
              "      <td>49974</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9186</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62974</th>\n",
              "      <td>49975</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.737</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-0.9900</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.758</td>\n",
              "      <td>0.096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62975</th>\n",
              "      <td>49976</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.8720</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62976</th>\n",
              "      <td>49977</td>\n",
              "      <td>-0.2263</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9559</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62977</th>\n",
              "      <td>49978</td>\n",
              "      <td>0.3818</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.536</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.785</td>\n",
              "      <td>0.164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62978</th>\n",
              "      <td>49979</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9383</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.801</td>\n",
              "      <td>0.112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62979</th>\n",
              "      <td>49980</td>\n",
              "      <td>-0.5719</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.654</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9584</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.730</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62980</th>\n",
              "      <td>49981</td>\n",
              "      <td>-0.7717</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.427</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.6486</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.799</td>\n",
              "      <td>0.112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62981</th>\n",
              "      <td>49982</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9987</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.698</td>\n",
              "      <td>0.217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62982</th>\n",
              "      <td>49983</td>\n",
              "      <td>-0.4019</td>\n",
              "      <td>0.351</td>\n",
              "      <td>0.649</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.1779</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62983</th>\n",
              "      <td>49984</td>\n",
              "      <td>-0.5106</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.476</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9999</td>\n",
              "      <td>0.231</td>\n",
              "      <td>0.677</td>\n",
              "      <td>0.093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62984</th>\n",
              "      <td>49985</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9898</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62985</th>\n",
              "      <td>49986</td>\n",
              "      <td>-0.4767</td>\n",
              "      <td>0.383</td>\n",
              "      <td>0.617</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.6199</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.761</td>\n",
              "      <td>0.117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62986</th>\n",
              "      <td>49987</td>\n",
              "      <td>-0.5994</td>\n",
              "      <td>0.494</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9790</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62987</th>\n",
              "      <td>49988</td>\n",
              "      <td>-0.6908</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.460</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9906</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.794</td>\n",
              "      <td>0.146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62988</th>\n",
              "      <td>49989</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9865</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.807</td>\n",
              "      <td>0.121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62989</th>\n",
              "      <td>49990</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8122</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.841</td>\n",
              "      <td>0.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62990</th>\n",
              "      <td>49991</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.6597</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.865</td>\n",
              "      <td>0.065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62991</th>\n",
              "      <td>49992</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.8176</td>\n",
              "      <td>0.117</td>\n",
              "      <td>0.756</td>\n",
              "      <td>0.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62992</th>\n",
              "      <td>49993</td>\n",
              "      <td>0.2023</td>\n",
              "      <td>0.245</td>\n",
              "      <td>0.319</td>\n",
              "      <td>0.436</td>\n",
              "      <td>0.9950</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62993</th>\n",
              "      <td>49994</td>\n",
              "      <td>-0.2732</td>\n",
              "      <td>0.344</td>\n",
              "      <td>0.656</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.9940</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.692</td>\n",
              "      <td>0.124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62994</th>\n",
              "      <td>49995</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9106</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62995</th>\n",
              "      <td>49996</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9287</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62996</th>\n",
              "      <td>49997</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.291</td>\n",
              "      <td>0.9997</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.858</td>\n",
              "      <td>0.092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62997</th>\n",
              "      <td>49998</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.7490</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62998</th>\n",
              "      <td>49999</td>\n",
              "      <td>-0.4939</td>\n",
              "      <td>0.516</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.0772</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.860</td>\n",
              "      <td>0.072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62999 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  title_senti_neg  title_senti_neu  title_senti_pos  \\\n",
              "0               0           0.4588            0.000            0.625   \n",
              "1               1           0.0000            0.000            1.000   \n",
              "2               2           0.0000            0.000            1.000   \n",
              "3               3          -0.7783            0.430            0.570   \n",
              "4               4           0.0000            0.000            1.000   \n",
              "5               5          -0.2500            0.250            0.750   \n",
              "6               6          -0.3400            0.107            0.893   \n",
              "7               7          -0.4588            0.317            0.528   \n",
              "8               8           0.3400            0.102            0.678   \n",
              "9               9          -0.4019            0.243            0.608   \n",
              "10             10           0.0000            0.000            1.000   \n",
              "11             11          -0.3818            0.302            0.698   \n",
              "12             12           0.4404            0.000            0.791   \n",
              "13             13          -0.4215            0.259            0.741   \n",
              "14             14          -0.2500            0.222            0.778   \n",
              "15             15           0.4019            0.000            0.769   \n",
              "16             16           0.4019            0.000            0.769   \n",
              "17             17           0.5106            0.000            0.675   \n",
              "18             18           0.0000            0.000            1.000   \n",
              "19             19           0.6597            0.172            0.312   \n",
              "20             20           0.3182            0.163            0.588   \n",
              "21             21          -0.3400            0.230            0.618   \n",
              "22             22           0.1027            0.198            0.581   \n",
              "23             23           0.4215            0.000            0.823   \n",
              "24             24           0.0000            0.000            1.000   \n",
              "25             25           0.4404            0.000            0.756   \n",
              "26             26          -0.7506            0.368            0.632   \n",
              "27             27           0.0000            0.000            1.000   \n",
              "28             28           0.0000            0.000            1.000   \n",
              "29             29           0.0000            0.000            1.000   \n",
              "...           ...              ...              ...              ...   \n",
              "62969       49970           0.4215            0.000            0.588   \n",
              "62970       49971          -0.4767            0.307            0.693   \n",
              "62971       49972           0.0000            0.000            1.000   \n",
              "62972       49973           0.0000            0.000            1.000   \n",
              "62973       49974           0.0000            0.000            1.000   \n",
              "62974       49975           0.3612            0.000            0.737   \n",
              "62975       49976           0.0000            0.000            1.000   \n",
              "62976       49977          -0.2263            0.213            0.787   \n",
              "62977       49978           0.3818            0.000            0.536   \n",
              "62978       49979           0.0000            0.000            1.000   \n",
              "62979       49980          -0.5719            0.346            0.654   \n",
              "62980       49981          -0.7717            0.573            0.427   \n",
              "62981       49982           0.0000            0.000            1.000   \n",
              "62982       49983          -0.4019            0.351            0.649   \n",
              "62983       49984          -0.5106            0.524            0.476   \n",
              "62984       49985           0.0000            0.000            1.000   \n",
              "62985       49986          -0.4767            0.383            0.617   \n",
              "62986       49987          -0.5994            0.494            0.506   \n",
              "62987       49988          -0.6908            0.540            0.460   \n",
              "62988       49989           0.0000            0.000            1.000   \n",
              "62989       49990           0.0000            0.000            1.000   \n",
              "62990       49991           0.0000            0.000            1.000   \n",
              "62991       49992           0.0000            0.000            1.000   \n",
              "62992       49993           0.2023            0.245            0.319   \n",
              "62993       49994          -0.2732            0.344            0.656   \n",
              "62994       49995           0.0000            0.000            1.000   \n",
              "62995       49996           0.0000            0.000            1.000   \n",
              "62996       49997           0.1779            0.223            0.485   \n",
              "62997       49998           0.0000            0.000            1.000   \n",
              "62998       49999          -0.4939            0.516            0.484   \n",
              "\n",
              "       title_senti_cmpd  text_senti_neg  text_senti_neu  text_senti_pos  \\\n",
              "0                 0.375         -0.3400           0.209           0.606   \n",
              "1                 0.000         -0.2960           0.063           0.887   \n",
              "2                 0.000          0.8957           0.021           0.871   \n",
              "3                 0.000          0.8316           0.133           0.517   \n",
              "4                 0.000          0.9517           0.066           0.765   \n",
              "5                 0.000         -0.9936           0.352           0.618   \n",
              "6                 0.000         -0.9559           0.103           0.813   \n",
              "7                 0.154         -0.9836           0.138           0.844   \n",
              "8                 0.220          0.1027           0.044           0.902   \n",
              "9                 0.149         -0.8402           0.151           0.809   \n",
              "10                0.000          0.0000           0.000           0.000   \n",
              "11                0.000          0.9933           0.020           0.836   \n",
              "12                0.209          0.9917           0.024           0.842   \n",
              "13                0.000         -0.9607           0.148           0.775   \n",
              "14                0.000          0.0000           0.000           1.000   \n",
              "15                0.231          0.7964           0.059           0.674   \n",
              "16                0.231          0.0000           0.000           1.000   \n",
              "17                0.325         -0.9783           0.180           0.719   \n",
              "18                0.000          0.8481           0.082           0.782   \n",
              "19                0.516          0.9899           0.079           0.706   \n",
              "20                0.248          0.9531           0.041           0.772   \n",
              "21                0.152         -0.8750           0.435           0.565   \n",
              "22                0.221         -0.8481           0.211           0.722   \n",
              "23                0.177         -0.6124           0.113           0.789   \n",
              "24                0.000          0.7184           0.000           0.759   \n",
              "25                0.244          0.4215           0.000           0.877   \n",
              "26                0.000         -0.9924           0.173           0.785   \n",
              "27                0.000          0.8402           0.056           0.838   \n",
              "28                0.000         -0.7269           0.251           0.539   \n",
              "29                0.000          0.8779           0.000           0.760   \n",
              "...                 ...             ...             ...             ...   \n",
              "62969             0.412          0.9968           0.096           0.727   \n",
              "62970             0.000         -0.8625           0.063           0.920   \n",
              "62971             0.000          0.2434           0.096           0.805   \n",
              "62972             0.000          0.9643           0.035           0.878   \n",
              "62973             0.000         -0.9186           0.087           0.855   \n",
              "62974             0.263         -0.9900           0.146           0.758   \n",
              "62975             0.000         -0.8720           0.078           0.900   \n",
              "62976             0.000          0.9559           0.039           0.872   \n",
              "62977             0.464          0.9980           0.051           0.785   \n",
              "62978             0.000          0.9383           0.087           0.801   \n",
              "62979             0.000         -0.9584           0.144           0.730   \n",
              "62980             0.000          0.6486           0.089           0.799   \n",
              "62981             0.000          0.9987           0.085           0.698   \n",
              "62982             0.000         -0.1779           0.104           0.820   \n",
              "62983             0.000         -0.9999           0.231           0.677   \n",
              "62984             0.000          0.9898           0.042           0.853   \n",
              "62985             0.000         -0.6199           0.122           0.761   \n",
              "62986             0.000         -0.9790           0.103           0.855   \n",
              "62987             0.000          0.9906           0.060           0.794   \n",
              "62988             0.000          0.9865           0.072           0.807   \n",
              "62989             0.000          0.8122           0.075           0.841   \n",
              "62990             0.000         -0.6597           0.070           0.865   \n",
              "62991             0.000         -0.8176           0.117           0.756   \n",
              "62992             0.436          0.9950           0.100           0.725   \n",
              "62993             0.000         -0.9940           0.184           0.692   \n",
              "62994             0.000          0.9106           0.070           0.833   \n",
              "62995             0.000          0.9287           0.076           0.815   \n",
              "62996             0.291          0.9997           0.050           0.858   \n",
              "62997             0.000          0.7490           0.067           0.848   \n",
              "62998             0.000         -0.0772           0.068           0.860   \n",
              "\n",
              "       text_senti_cmp  \n",
              "0               0.185  \n",
              "1               0.050  \n",
              "2               0.108  \n",
              "3               0.350  \n",
              "4               0.170  \n",
              "5               0.030  \n",
              "6               0.084  \n",
              "7               0.019  \n",
              "8               0.054  \n",
              "9               0.040  \n",
              "10              0.000  \n",
              "11              0.144  \n",
              "12              0.134  \n",
              "13              0.077  \n",
              "14              0.000  \n",
              "15              0.267  \n",
              "16              0.000  \n",
              "17              0.101  \n",
              "18              0.136  \n",
              "19              0.214  \n",
              "20              0.187  \n",
              "21              0.000  \n",
              "22              0.067  \n",
              "23              0.098  \n",
              "24              0.241  \n",
              "25              0.123  \n",
              "26              0.042  \n",
              "27              0.106  \n",
              "28              0.210  \n",
              "29              0.240  \n",
              "...               ...  \n",
              "62969           0.178  \n",
              "62970           0.018  \n",
              "62971           0.099  \n",
              "62972           0.087  \n",
              "62973           0.058  \n",
              "62974           0.096  \n",
              "62975           0.022  \n",
              "62976           0.089  \n",
              "62977           0.164  \n",
              "62978           0.112  \n",
              "62979           0.125  \n",
              "62980           0.112  \n",
              "62981           0.217  \n",
              "62982           0.076  \n",
              "62983           0.093  \n",
              "62984           0.105  \n",
              "62985           0.117  \n",
              "62986           0.042  \n",
              "62987           0.146  \n",
              "62988           0.121  \n",
              "62989           0.084  \n",
              "62990           0.065  \n",
              "62991           0.127  \n",
              "62992           0.175  \n",
              "62993           0.124  \n",
              "62994           0.097  \n",
              "62995           0.109  \n",
              "62996           0.092  \n",
              "62997           0.085  \n",
              "62998           0.072  \n",
              "\n",
              "[62999 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Pc64WKe98sMt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert sentiment_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBBX3ClJrpP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyunwook (James)"
      ]
    },
    {
      "metadata": {
        "id": "vgZ1J_7WtJEi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "News event coverage scores ranging from 0 to 18 are added to the dataset"
      ]
    },
    {
      "metadata": {
        "id": "8N8r9LMprrLy",
        "colab_type": "code",
        "outputId": "e5cf29c2-25d7-4d66-b324-d3c7629a4125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "coverage_factor = get_parsed_data('https://github.com/synle/AlternusVera/releases/download/v0/all_data_coverage_condensed.processed.csv')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "b5xA0mzMwU6s",
        "colab_type": "code",
        "outputId": "454794ec-967e-4cdf-c5d0-4b2280c654cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "coverage_factor.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>Coverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Govâ€™t B...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Hillary Goes Absolutely Berserk On Protester A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>BREAKING! NYPD Ready To Make Arrests In Weiner...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>BREAKING: CLINTON CLEARED...Was This A Coordin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"â€¦Burn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                              title  Coverage\n",
              "0           0  Muslims BUSTED: They Stole Millions In Govâ€™t B...         0\n",
              "1           1  Re: Why Did Attorney General Loretta Lynch Ple...         0\n",
              "2           2  BREAKING: Weiner Cooperating With FBI On Hilla...         0\n",
              "3           3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...         0\n",
              "4           4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...         0\n",
              "5           5  Hillary Goes Absolutely Berserk On Protester A...         0\n",
              "6           6  BREAKING! NYPD Ready To Make Arrests In Weiner...         0\n",
              "7           7  WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...         0\n",
              "8           8  BREAKING: CLINTON CLEARED...Was This A Coordin...         0\n",
              "9           9  EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"â€¦Burn...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "fhojyGgZ9PoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert coverage_factor.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YB6iIc4TrsiU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sy"
      ]
    },
    {
      "metadata": {
        "id": "x3_d45Insa7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we have 3 scores for reputation and social activeness, and all of them ranges from 0 to 10\n",
        "\n",
        "*   calculated_reputation_score\n",
        "*   calculated_spam_score\n",
        "*   calculated_social_score"
      ]
    },
    {
      "metadata": {
        "id": "V7kWJVbtrt_X",
        "colab_type": "code",
        "outputId": "7fa0d184-1086-4f71-cfd4-22b36eacf379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "social_reliability_factors = get_parsed_data('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/factor_social_reliablity.csv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTLDLgg6r9X9",
        "colab_type": "code",
        "outputId": "15d1a459-5623-49b4-c130-54be5dd440cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "social_reliability_factors"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>type</th>\n",
              "      <th>calculated_reputation_score</th>\n",
              "      <th>calculated_spam_score</th>\n",
              "      <th>calculated_social_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8.65</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>7.01</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>9.95</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>9.98</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2.56</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62969</th>\n",
              "      <td>49970</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62970</th>\n",
              "      <td>49971</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62971</th>\n",
              "      <td>49972</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62972</th>\n",
              "      <td>49973</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62973</th>\n",
              "      <td>49974</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62974</th>\n",
              "      <td>49975</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62975</th>\n",
              "      <td>49976</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62976</th>\n",
              "      <td>49977</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62977</th>\n",
              "      <td>49978</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62978</th>\n",
              "      <td>49979</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62979</th>\n",
              "      <td>49980</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62980</th>\n",
              "      <td>49981</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62981</th>\n",
              "      <td>49982</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62982</th>\n",
              "      <td>49983</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62983</th>\n",
              "      <td>49984</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62984</th>\n",
              "      <td>49985</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62985</th>\n",
              "      <td>49986</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62986</th>\n",
              "      <td>49987</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62987</th>\n",
              "      <td>49988</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62988</th>\n",
              "      <td>49989</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62989</th>\n",
              "      <td>49990</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62990</th>\n",
              "      <td>49991</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62991</th>\n",
              "      <td>49992</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62992</th>\n",
              "      <td>49993</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62993</th>\n",
              "      <td>49994</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62994</th>\n",
              "      <td>49995</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62995</th>\n",
              "      <td>49996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62996</th>\n",
              "      <td>49997</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62997</th>\n",
              "      <td>49998</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62998</th>\n",
              "      <td>49999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62999 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  type  calculated_reputation_score  calculated_spam_score  \\\n",
              "0               0     0                            8                   0.00   \n",
              "1               1     0                            8                   0.00   \n",
              "2               2     0                            8                   0.00   \n",
              "3               3     0                            8                   0.68   \n",
              "4               4     0                            8                   8.65   \n",
              "5               5     0                            8                   0.00   \n",
              "6               6     0                            8                   7.01   \n",
              "7               7     0                            8                   1.88   \n",
              "8               8     0                            8                   1.44   \n",
              "9               9     0                            8                   9.95   \n",
              "10             10     0                            8                   0.00   \n",
              "11             11     0                            8                   9.98   \n",
              "12             12     0                            8                   0.00   \n",
              "13             13     0                            8                   0.01   \n",
              "14             14     0                            8                   0.00   \n",
              "15             15     0                            8                   0.00   \n",
              "16             16     0                            8                   2.68   \n",
              "17             17     0                            8                   0.00   \n",
              "18             18     0                            8                   0.00   \n",
              "19             19     0                            8                   0.00   \n",
              "20             20     0                            8                   1.90   \n",
              "21             21     0                            8                   0.00   \n",
              "22             22     0                            8                   0.00   \n",
              "23             23     0                            8                   0.00   \n",
              "24             24     0                            8                   0.00   \n",
              "25             25     0                            8                   0.00   \n",
              "26             26     0                            8                   0.00   \n",
              "27             27     0                            8                   2.56   \n",
              "28             28     0                            8                   0.00   \n",
              "29             29     0                            8                   0.00   \n",
              "...           ...   ...                          ...                    ...   \n",
              "62969       49970     0                            0                   0.00   \n",
              "62970       49971     0                            0                   0.00   \n",
              "62971       49972     0                            0                   0.00   \n",
              "62972       49973     0                            0                   0.00   \n",
              "62973       49974     0                            0                   0.00   \n",
              "62974       49975     0                            0                   0.00   \n",
              "62975       49976     0                            0                   0.00   \n",
              "62976       49977     0                            0                   0.00   \n",
              "62977       49978     0                            0                   0.00   \n",
              "62978       49979     0                            0                   0.00   \n",
              "62979       49980     0                            0                   0.00   \n",
              "62980       49981     0                            0                   0.00   \n",
              "62981       49982     0                            0                   0.00   \n",
              "62982       49983     0                            0                   0.00   \n",
              "62983       49984     0                            0                   0.00   \n",
              "62984       49985     0                            0                   0.00   \n",
              "62985       49986     0                            0                   0.00   \n",
              "62986       49987     0                            0                   0.00   \n",
              "62987       49988     0                            0                   0.00   \n",
              "62988       49989     0                            0                   0.00   \n",
              "62989       49990     0                            0                   0.00   \n",
              "62990       49991     0                            0                   0.00   \n",
              "62991       49992     0                            0                   0.00   \n",
              "62992       49993     0                            0                   0.00   \n",
              "62993       49994     0                            0                   0.00   \n",
              "62994       49995     0                            0                   0.00   \n",
              "62995       49996     0                            0                   0.00   \n",
              "62996       49997     0                            0                   0.00   \n",
              "62997       49998     0                            0                   0.00   \n",
              "62998       49999     0                            0                   0.00   \n",
              "\n",
              "       calculated_social_score  \n",
              "0                        0.011  \n",
              "1                        0.011  \n",
              "2                        0.011  \n",
              "3                        0.000  \n",
              "4                        0.000  \n",
              "5                        0.011  \n",
              "6                        0.000  \n",
              "7                        0.000  \n",
              "8                        0.000  \n",
              "9                        0.000  \n",
              "10                       0.011  \n",
              "11                       0.000  \n",
              "12                       0.011  \n",
              "13                       0.000  \n",
              "14                       0.000  \n",
              "15                       0.011  \n",
              "16                       0.000  \n",
              "17                       0.011  \n",
              "18                       0.011  \n",
              "19                       0.011  \n",
              "20                       0.000  \n",
              "21                       0.011  \n",
              "22                       0.011  \n",
              "23                       0.011  \n",
              "24                       0.011  \n",
              "25                       0.011  \n",
              "26                       0.011  \n",
              "27                       0.000  \n",
              "28                       0.011  \n",
              "29                       0.011  \n",
              "...                        ...  \n",
              "62969                    0.000  \n",
              "62970                    0.000  \n",
              "62971                    0.000  \n",
              "62972                    0.000  \n",
              "62973                    0.000  \n",
              "62974                    0.000  \n",
              "62975                    0.000  \n",
              "62976                    0.000  \n",
              "62977                    0.000  \n",
              "62978                    0.000  \n",
              "62979                    0.000  \n",
              "62980                    0.000  \n",
              "62981                    0.000  \n",
              "62982                    0.000  \n",
              "62983                    0.000  \n",
              "62984                    0.000  \n",
              "62985                    0.000  \n",
              "62986                    0.000  \n",
              "62987                    0.000  \n",
              "62988                    0.000  \n",
              "62989                    0.000  \n",
              "62990                    0.000  \n",
              "62991                    0.000  \n",
              "62992                    0.000  \n",
              "62993                    0.000  \n",
              "62994                    0.000  \n",
              "62995                    0.000  \n",
              "62996                    0.000  \n",
              "62997                    0.000  \n",
              "62998                    0.000  \n",
              "\n",
              "[62999 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "RHmSgvNC9U1H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert social_reliability_factors.shape[0] == 62999, \"Please review your csv\" # INSERTED BY JAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XxeYDeRwrutT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Lin"
      ]
    },
    {
      "metadata": {
        "id": "4-Nv-IOyrwJO",
        "colab_type": "code",
        "outputId": "8451cc0d-342b-476a-e599-4c07fe4d1449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "\n",
        "def get_parsed_data2(url):\n",
        "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer', error_bad_lines=False)\n",
        "\n",
        "# download and parse the dataset...\n",
        "data_kg_fake_news2 = get_parsed_data2('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "keb914mJnqRA",
        "colab_type": "code",
        "outputId": "b3497497-2e6b-4563-ffda-254d806c8e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "data_kg_nonfake_news2 = get_parsed_data2('https://github.com/synle/AlternusVera/releases/download/v0/articles1.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HTfr4_5QoZ6c",
        "colab_type": "code",
        "outputId": "50f8ef0a-5ed4-48b9-d056-62a7900f8233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "data_kg_nonfake_news2.rename(columns={\"content\": \"text\"}, inplace=True)\n",
        "data_kg_nonfake_news2['type'] = 'non-bs'\n",
        "print(data_kg_nonfake_news2.shape)\n",
        "data_kg_nonfake_news2.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>publication</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>17283</td>\n",
              "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Carl Hulse</td>\n",
              "      <td>2016-12-31</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WASHINGTON  â€”   Congressional Republicans have...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>17284</td>\n",
              "      <td>Rift Between Officers and Residents as Killing...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Benjamin Mueller and Al Baker</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>After the bullet shells get counted, the blood...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17285</td>\n",
              "      <td>Tyrus Wong, â€˜Bambiâ€™ Artist Thwarted by Racial ...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Margalit Fox</td>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When Walt Disneyâ€™s â€œBambiâ€ opened in 1942, cri...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17286</td>\n",
              "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>William McDonald</td>\n",
              "      <td>2017-04-10</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Death may be the great equalizer, but it isnâ€™t...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17287</td>\n",
              "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Choe Sang-Hun</td>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SEOUL, South Korea  â€”   North Koreaâ€™s leader, ...</td>\n",
              "      <td>non-bs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     id                                              title  \\\n",
              "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
              "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
              "2           2  17285  Tyrus Wong, â€˜Bambiâ€™ Artist Thwarted by Racial ...   \n",
              "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
              "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
              "\n",
              "      publication                         author        date    year  month  \\\n",
              "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
              "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
              "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
              "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
              "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
              "\n",
              "   url                                               text    type  \n",
              "0  NaN  WASHINGTON  â€”   Congressional Republicans have...  non-bs  \n",
              "1  NaN  After the bullet shells get counted, the blood...  non-bs  \n",
              "2  NaN  When Walt Disneyâ€™s â€œBambiâ€ opened in 1942, cri...  non-bs  \n",
              "3  NaN  Death may be the great equalizer, but it isnâ€™t...  non-bs  \n",
              "4  NaN  SEOUL, South Korea  â€”   North Koreaâ€™s leader, ...  non-bs  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "WNJtZRjQogz4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Combine those two datasets, mark data \"bias 443 bs 11492 conspiracy 430 fake 19 hate 246 junksci 102 satire 146 state 121\" to \"bs\"."
      ]
    },
    {
      "metadata": {
        "id": "AToqf_k1oc-Y",
        "colab_type": "code",
        "outputId": "c896d3cc-10a6-474a-e43a-1dbc59896b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import word_tokenize\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from string import punctuation\n",
        "from nltk import PorterStemmer\n",
        "import copy \n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "cachedStopWords = set(stopwords.words('english') + list(punctuation) + [''])\n",
        "print(data_kg_fake_news2.shape)\n",
        "print(data_kg_fake_news2.groupby(['type'])['type'].count())\n",
        "\n",
        "print(data_kg_nonfake_news2.shape)\n",
        "print(data_kg_nonfake_news2.groupby(['type'])['type'].count())\n",
        "\n",
        "data_kg_fake_news_b2=copy.deepcopy(data_kg_fake_news2);\n",
        "data_kg_fake_news_b2.loc[data_kg_fake_news_b2['type']!='non-bs', 'type'] = 'bs'\n",
        "\n",
        "all_data2 = pd.concat([data_kg_fake_news_b2[['text','type']], data_kg_nonfake_news2[['text','type']]])\n",
        "\n",
        "print(all_data2.groupby(['type'])['type'].count())\n",
        "\n",
        "print(all_data2.shape)\n",
        "X2=all_data2['text'].astype('U')\n",
        "y2=all_data2['type']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "(12999, 20)\n",
            "type\n",
            "bias            443\n",
            "bs            11492\n",
            "conspiracy      430\n",
            "fake             19\n",
            "hate            246\n",
            "junksci         102\n",
            "satire          146\n",
            "state           121\n",
            "Name: type, dtype: int64\n",
            "(50000, 11)\n",
            "type\n",
            "non-bs    50000\n",
            "Name: type, dtype: int64\n",
            "type\n",
            "bs        12999\n",
            "non-bs    50000\n",
            "Name: type, dtype: int64\n",
            "(62999, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ce5oPqjOqHox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now try to use TfidfVectorizer to get a matrix for further classification. Also tried applying SVD for dimension reduction."
      ]
    },
    {
      "metadata": {
        "id": "87NenXuEqIl7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder, Imputer, MaxAbsScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3)\n",
        "\n",
        "def tokenize2(text):\n",
        "    min_length = 3\n",
        "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "    words = [word for word in words if word not in cachedStopWords]\n",
        "    tokens = list(map(lambda token: PorterStemmer().stem(token), words))\n",
        "    p = re.compile('[a-zA-Z]+')\n",
        "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token) >= min_length, tokens))\n",
        "    return filtered_tokens\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenize2)\n",
        "svd_model = TruncatedSVD(n_components=200,       \n",
        "                         algorithm='randomized',\n",
        "                         n_iter=10)\n",
        "# svd_transformer = Pipeline([('tfidf', vectorizer), \n",
        "#                             ('svd', svd_model)])\n",
        "svd_transformer=vectorizer\n",
        "    \n",
        "vectorised_train_documents = svd_transformer.fit_transform(X_train2)\n",
        "vectorised_test_documents = svd_transformer.transform(X_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YL5cEiNCqO5t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now do modeling and tuning\n",
        "- Random forest  \n",
        "- Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "pXVV28AyqSCA",
        "colab_type": "code",
        "outputId": "20fdc289-0bb7-42f8-b13b-b0ed24c0f049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "gs=RandomForestClassifier()\n",
        "gs.fit(vectorised_train_documents, y_train2)\n",
        "print(vectorised_train_documents.shape)\n",
        "feature_imp = pd.Series(gs.feature_importances_,index=list(vectorizer.get_feature_names())).sort_values(ascending=False).nlargest(20)\n",
        "print(feature_imp)\n",
        "\n",
        "y_pred2=gs.predict(vectorised_test_documents)\n",
        "print(y_test2.value_counts(sort=False))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(metrics.confusion_matrix(y_test2, y_pred2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(44099, 176611)\n",
            "u.s.        0.017774\n",
            "n't         0.012012\n",
            "said        0.010244\n",
            "follow      0.007260\n",
            "twitter     0.005065\n",
            "octob       0.004312\n",
            "so-cal      0.004039\n",
            "clinton     0.003953\n",
            "cnn         0.003468\n",
            "advertis    0.003353\n",
            "email       0.003335\n",
            "presid      0.003282\n",
            "http        0.003145\n",
            "last        0.002911\n",
            "new         0.002845\n",
            "share       0.002813\n",
            "hillari     0.002657\n",
            "told        0.002509\n",
            "novemb      0.002402\n",
            "pleas       0.002361\n",
            "dtype: float64\n",
            "bs         3904\n",
            "non-bs    14996\n",
            "Name: type, dtype: int64\n",
            "Accuracy: 0.8884656084656085\n",
            "[[ 2056  1848]\n",
            " [  260 14736]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5INVTKsxDJq",
        "colab_type": "code",
        "outputId": "4e0cb3ed-06d9-4e7e-d69c-c5afb18d5148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "# logistic = LogisticRegression()\n",
        "# logistic = LogisticRegression(class_weight='balanced')\n",
        "logistic = LogisticRegression(class_weight={\"bs\":5,\"non-bs\":3})\n",
        "C = [0.1, 1]\n",
        "penalty = ['l1','l2']\n",
        "\n",
        "param_grid = dict(C=C, penalty=penalty)\n",
        "gs = GridSearchCV(logistic, param_grid=param_grid, cv= 5, scoring='accuracy')\n",
        "\n",
        "gs.fit(vectorised_train_documents, y_train2)\n",
        "print(gs.best_params_)\n",
        "\n",
        "y_pred2=gs.predict(vectorised_test_documents)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(\"F1:\",metrics.f1_score(y_test2, y_pred2, pos_label='bs'))\n",
        "print(metrics.confusion_matrix(y_test2, y_pred2))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'penalty': 'l1'}\n",
            "Accuracy: 0.9568253968253968\n",
            "F1: 0.8950347311551327\n",
            "[[ 3479   425]\n",
            " [  391 14605]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UGZUfsw4bdcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So by trying different algorithms and model tuning, eventually we found weighted **LogisticRegression** gives pretty good result with accuracy** 95.6%** and parameters LogisticRegression(class_weight={\"bs\":5,\"non-bs\":3}, {'C': 1, 'penalty': 'l1'})  upon raw **TF-IDF** factors.\n",
        "  \n",
        "  Now we can use the model on news like below:"
      ]
    },
    {
      "metadata": {
        "id": "m8BfxET1b7Uv",
        "colab_type": "code",
        "outputId": "6217ee0c-9d2d-40b5-9af0-649db32adce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = np.array([\"Had President Donald Trump been successful in launching prosecutions against Hillary Clinton and James Comey, it could have spelled the end of his presidency, as a clear-cut abuse of power.\\\n",
        "It never happened, apparently thwarted by then-White House Counsel Don McGahn and other senior officials. But that does not mean this is a crisis dodged for Trump and he is now free from fresh legal and political jeopardy. Quite the reverse.\\\n",
        "RELATED: Trump raised prosecuting Clinton with top White House, Justice officials\\\n",
        "At the very least, the latest developments underline how Trump's senior subordinates may have shielded a President unschooled in constitutional norms from disastrous steps that could have put his presidency in peril.\\\n",
        "And it leaves anyone on the outside wondering what other potential disasters top officials like McGahn, former Attorney General Jeff Sessions and current Deputy Attorney General Rod Rosenstein might have prevented.\\\n",
        "They also raise questions about the capacity of a now-understaffed White House and legal counsel's operation to protect the President from current or future transgressions.\\\n",
        "It will be impossible to confirm, given the habitual silence from the special counsel's office, but the revelations hint at the possibility that Robert Mueller knows much more about what went on in the corridors of the West Wing than has been publicly revealed.\\\n",
        "That will play into rising tensions in Washington amid expectations that the endgame of Mueller's probe is in sight and speculation about possible indictments targeting Trump world and the content of his final report.\\\n",
        "Bombshell reports by CNN and The New York Times about the President's intentions emerged on another surreal day in Washington that saw shocking disclosures about Ivanka Trump's emails and a huge foreign policy pivot over Saudi Arabia.\"])\n",
        "s = pd.Series(data)\n",
        "\n",
        "vectorised_test_documents = svd_transformer.transform(s)\n",
        "y_pred=gs.predict(vectorised_test_documents)\n",
        "print(y_pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['non-bs']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PsqeexTHscMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Aggregation"
      ]
    },
    {
      "metadata": {
        "id": "KMON1jgLB7q_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is where the magic happens. Please ensure that your dataframe follows\n",
        "the dimensions, and integrate your factor columns to **all_data**."
      ]
    },
    {
      "metadata": {
        "id": "M4-yEA3zsbvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Aggregate Multiple CSV Data into One Data Frame\n",
        "\n",
        "# #################################################################################################################################\n",
        "# Only include ones that passed the 62999 Test\n",
        "# This is important because the columns have -----------------------------------------------------+-------------------------------+\n",
        "# to align                                                                                        | (Add your name here)          | (Factor)\n",
        "# ############################################                                                    V                               V\n",
        "\n",
        "all_data[ 'Coverage' ]    = coverage_factor[ 'Coverage' ]                                     # <-- HYUNWOOK (JAMES)              News Coverage\n",
        "all_data[ 'Reputation' ]  = social_reliability_factors[ 'calculated_reputation_score' ]       # <-- SY                            Social Reliability\n",
        "all_data[ 'Spam' ]        = social_reliability_factors[ 'calculated_spam_score' ]             # <-- SY\n",
        "all_data[ 'Social' ]      = social_reliability_factors[ 'calculated_social_score' ]           # <-- SY\n",
        "all_data[ 'title_senti_neg' ]  = sentiment_factors[ 'title_senti_neg' ]                       # <-- MOJDEH                        Sentiment\n",
        "all_data[ 'title_senti_neu' ]  = sentiment_factors[ 'title_senti_neu' ]                       # <-- MOJDEH\n",
        "all_data[ 'title_senti_pos'\t]  = sentiment_factors[ 'title_senti_pos'\t]                       # <-- MOJDEH\n",
        "all_data[ 'title_senti_cmp' ]  = sentiment_factors[ 'title_senti_cmpd' ]                      # <-- MOJDEH\n",
        "all_data[ 'text_senti_neg' ]   = sentiment_factors[ 'text_senti_neg' ]                        # <-- MOJDEH\n",
        "all_data[ 'text_senti_neu' ]   = sentiment_factors[ 'text_senti_neu' ]                        # <-- MOJDEH\n",
        "all_data[ 'text_senti_pos' ]   = sentiment_factors[ 'text_senti_pos' ]                        # <-- MOJDEH\n",
        "all_data[ 'text_senti_cmp' ]   = sentiment_factors[ 'text_senti_cmp' ]                        # <-- MOJDEH\n",
        "all_data[['text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean']] = w2v_d2v_factors[['text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VuirfyNm_8Fa",
        "colab_type": "code",
        "outputId": "2eaa471d-4596-40ed-b560-5b46a3e37c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "all_data.head(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Reputation</th>\n",
              "      <th>Spam</th>\n",
              "      <th>Social</th>\n",
              "      <th>title_senti_neg</th>\n",
              "      <th>title_senti_neu</th>\n",
              "      <th>title_senti_pos</th>\n",
              "      <th>title_senti_cmp</th>\n",
              "      <th>text_senti_neg</th>\n",
              "      <th>text_senti_neu</th>\n",
              "      <th>text_senti_pos</th>\n",
              "      <th>text_senti_cmp</th>\n",
              "      <th>text_w2v_mean</th>\n",
              "      <th>title_w2v_mean</th>\n",
              "      <th>text_d2v_mean</th>\n",
              "      <th>title_d2v_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Govâ€™t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.4588</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.375</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>0.209</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.185</td>\n",
              "      <td>-0.052476</td>\n",
              "      <td>0.066654</td>\n",
              "      <td>-0.220385</td>\n",
              "      <td>-0.114133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.887</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.126095</td>\n",
              "      <td>-0.309628</td>\n",
              "      <td>-0.048451</td>\n",
              "      <td>0.017952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
              "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8957</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.108</td>\n",
              "      <td>-0.095904</td>\n",
              "      <td>-0.209579</td>\n",
              "      <td>-0.118836</td>\n",
              "      <td>-0.079925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
              "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.7783</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.517</td>\n",
              "      <td>0.350</td>\n",
              "      <td>-0.027249</td>\n",
              "      <td>-0.071950</td>\n",
              "      <td>-0.038647</td>\n",
              "      <td>-0.168344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
              "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8.65</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.9517</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.170</td>\n",
              "      <td>-0.075030</td>\n",
              "      <td>-0.066515</td>\n",
              "      <td>-0.155317</td>\n",
              "      <td>-0.074950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Muslims BUSTED: They Stole Millions In Govâ€™t B...   \n",
              "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
              "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
              "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
              "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
              "\n",
              "                                                text  type  Coverage  \\\n",
              "0  Print They should pay all the back all the mon...     0         0   \n",
              "1  Why Did Attorney General Loretta Lynch Plead T...     0         0   \n",
              "2  Red State : \\nFox News Sunday reported this mo...     0         0   \n",
              "3  Email Kayla Mueller was a prisoner and torture...     0         0   \n",
              "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...     0         0   \n",
              "\n",
              "   Reputation  Spam  Social  title_senti_neg  title_senti_neu  \\\n",
              "0           8  0.00   0.011           0.4588             0.00   \n",
              "1           8  0.00   0.011           0.0000             0.00   \n",
              "2           8  0.00   0.011           0.0000             0.00   \n",
              "3           8  0.68   0.000          -0.7783             0.43   \n",
              "4           8  8.65   0.000           0.0000             0.00   \n",
              "\n",
              "   title_senti_pos  title_senti_cmp  text_senti_neg  text_senti_neu  \\\n",
              "0            0.625            0.375         -0.3400           0.209   \n",
              "1            1.000            0.000         -0.2960           0.063   \n",
              "2            1.000            0.000          0.8957           0.021   \n",
              "3            0.570            0.000          0.8316           0.133   \n",
              "4            1.000            0.000          0.9517           0.066   \n",
              "\n",
              "   text_senti_pos  text_senti_cmp  text_w2v_mean  title_w2v_mean  \\\n",
              "0           0.606           0.185      -0.052476        0.066654   \n",
              "1           0.887           0.050      -0.126095       -0.309628   \n",
              "2           0.871           0.108      -0.095904       -0.209579   \n",
              "3           0.517           0.350      -0.027249       -0.071950   \n",
              "4           0.765           0.170      -0.075030       -0.066515   \n",
              "\n",
              "   text_d2v_mean  title_d2v_mean  \n",
              "0      -0.220385       -0.114133  \n",
              "1      -0.048451        0.017952  \n",
              "2      -0.118836       -0.079925  \n",
              "3      -0.038647       -0.168344  \n",
              "4      -0.155317       -0.074950  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "3qF2DLXMI5PT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using RandomForrest Classifier To Determine Important Factors"
      ]
    },
    {
      "metadata": {
        "id": "MwP7ZRUsI4pG",
        "colab_type": "code",
        "outputId": "8ace1dc4-9a00-416b-8ef9-00a6727c6420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "########################################\n",
        "# UPDATE YOUR FACTOR HERE\n",
        "\n",
        "########################################\n",
        "X = all_data[['Coverage', 'Reputation', 'Spam', 'Social', 'title_senti_neg', 'title_senti_neu', 'title_senti_pos', 'title_senti_cmp', 'text_senti_neg', 'text_senti_neu', 'text_senti_pos', 'text_senti_cmp', 'text_w2v_mean','title_w2v_mean','text_d2v_mean','title_d2v_mean' ]]\n",
        "Y = all_data['type']\n",
        "\n",
        "X_train , X_test , Y_train , Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(X_train,Y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Z8nWAd8xJ1eL",
        "colab_type": "code",
        "outputId": "987bc2e5-6aac-4195-e87e-e28425e727ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = clf.predict(X_test)\n",
        "print('Accuracy Score Is:', metrics.accuracy_score(Y_test, Y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score Is: 0.8987830687830688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1s1lOcmWJ7BW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We got around 60~70% accuracy in determining if the news is fake or not."
      ]
    },
    {
      "metadata": {
        "id": "4v3M5nbSKASW",
        "colab_type": "code",
        "outputId": "81caa196-248f-449e-deae-b465c5932abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=list(X)).sort_values(ascending=False)\n",
        "sns.barplot(y=feature_imp, x=feature_imp.index)\n",
        "\n",
        "plt.ylabel('Importance Score')\n",
        "plt.xlabel('Factor Values')\n",
        "plt.legend()\n",
        "\n",
        "plt.gcf().set_size_inches(30, 10)\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9c99172717c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Importance Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Factor Values'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAFKCAYAAADrFq2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7bf51d45f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "a8luNboQLKrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now assign weights based on the importance score above"
      ]
    },
    {
      "metadata": {
        "id": "ki6ase2fsWyk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Polynomial Equation"
      ]
    },
    {
      "metadata": {
        "id": "qaaSug57sYl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define polynomial function\n",
        "all_data[ 'Score' ] = \\\n",
        "    all_data[ 'Coverage' ] * 10 + \\\n",
        "    all_data[ 'Reputation' ] * 10 + \\\n",
        "    all_data[ 'Spam' ]  * 10 + \\\n",
        "    all_data[ 'Social' ] * 200 + \\\n",
        "    all_data[ 'title_senti_neg' ] * 20 + \\\n",
        "    all_data[ 'title_senti_neu' ] + \\\n",
        "    all_data[ 'title_senti_pos'\t] * 20 + \\\n",
        "    all_data[ 'title_senti_cmp' ] + \\\n",
        "    all_data[ 'text_senti_neg' ] * 10 + \\\n",
        "    all_data[' text_senti_neu' ] + \\\n",
        "    all_data[ 'text_senti_pos' ] + \\\n",
        "    all_data[ 'text_senti_cmp' ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKaCQGDaGSeU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(all_data.type, all_data.Score )\n",
        "plt.xlabel( \"Fake News\" )\n",
        "plt.ylabel( \"Score\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNM0rxUxHFsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bins = range(0,3000,100)\n",
        "\n",
        "fake_data = all_data[all_data.type == 1 ]\n",
        "\n",
        "plt.hist(fake_data.Score, bins, histtype='bar', rwidth=0.8, cumulative=False )\n",
        "plt.xlabel( \"Poly Score\" )\n",
        "plt.ylabel( \"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "esbZdILMIs-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Distribution for Authentic Non-fake News"
      ]
    },
    {
      "metadata": {
        "id": "PV4ChgqHHJ86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "nonfake_data = all_data[all_data.type == 0 ]\n",
        "\n",
        "plt.hist(nonfake_data.Score, bins, histtype='bar', rwidth=0.8, cumulative=False )\n",
        "plt.xlabel( \"Poly Score\" )\n",
        "plt.ylabel( \"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzcwkBztMV97",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/synle/AlternusVera/releases/download/v0/fake_news_w2v_d2v_only.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E77MI-RLMby-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test = get_parsed_data(url)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}